{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import set_start_method\n",
    "import time\n",
    "import spacy\n",
    "import warnings\n",
    "import operator\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nlp =spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def get_paralel_similarity(tup):\n",
    "    start_time = time.time()\n",
    "    simi = tup[0].similarity(tup[1])\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return simi\n",
    "    \n",
    "class Matcher(object):\n",
    "    def __init__(self,**kwargs):\n",
    "        self.word = kwargs.get('word')\n",
    "        self.word_list = kwargs.get('word_list')\n",
    "        self.n = kwargs.get('n')\n",
    "        self.nlp = kwargs.get('nlp')\n",
    "        \n",
    "    def get_top_similarities(self):\n",
    "        pool = Pool(processes=3)  \n",
    "        similarities = {}\n",
    "        doc1 = nlp(str(self.word))\n",
    "        tup_list = []\n",
    "        for i in tqdm(self.word_list):\n",
    "            tup_list.append((doc1,i))\n",
    "\n",
    "        start_time = time.time()\n",
    "        similarities = pool.map(get_paralel_similarity, tup_list, chunksize=1)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        simi = {}\n",
    "        for i in tqdm(range(len(self.word_list))):\n",
    "            simi[self.word_list[i]] = similarities[i]\n",
    "        return sorted(simi.items(),key=operator.itemgetter(1),reverse=True)[:self.n]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"/Users/gadgethub/ontology/src/api_v2/others/emsi_ontology_complete.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = list(nlp.pipe(df[\"jobs\"]))\n",
    "matcher = Matcher(word=\"Data Scientist\",word_list=jobs,n=5,nlp=nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'get_similarity.<locals>.get_paralel_similarity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-14bfa5d27d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/gadgethub/ontology/src/api_v2/others/emsi_ontology_complete.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mget_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data scientist\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-14bfa5d27d33>\u001b[0m in \u001b[0;36mget_similarity\u001b[0;34m(doc1, df)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m# Create a multiprocessing Pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_paralel_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"jobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    429\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'get_similarity.<locals>.get_paralel_similarity'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "\n",
    "nlp =spacy.load(\"en_core_web_md\")\n",
    "start_time = time.time()\n",
    "\n",
    "def get_similarity(doc1, df):\n",
    "    def get_paralel_similarity(item):\n",
    "        return doc1.similarity(nlp(item))\n",
    "    if __name__ == '__main__':\n",
    "        pool = Pool()                         # Create a multiprocessing Pool\n",
    "        similarities = pool.map(get_paralel_similarity, list(df[\"jobs\"])) \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "df = pd.read_pickle(\"/Users/gadgethub/ontology/src/api_v2/others/emsi_ontology_complete.pkl\")\n",
    "get_similarity(\"data scientist\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "nlp =spacy.load(\"en_core_web_md\")\n",
    "start_time = time.time()\n",
    "doc1 = nlp(str(\"Data Scientist\"))\n",
    "\n",
    "\n",
    "def get_paralel_similarity(item):\n",
    "    return doc1.similarity(item)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool()                         # Create a multiprocessing Pool\n",
    "    lista = list(nlp.pipe(df[\"jobs\"]))\n",
    "    similarities = pool.map(get_paralel_similarity, lista)\n",
    "    pool.close()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3929/3929 [00:00<00:00, 285932.27it/s]\n"
     ]
    }
   ],
   "source": [
    "x = matcher.get_top_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"/Users/gadgethub/ontology/src/api_v2/others/emsi_ontology_complete.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3929/3929 [01:53<00:00, 34.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "skills = []\n",
    "for title in tqdm(df[\"jobs\"]):\n",
    "    response = requests.post('http://127.0.0.1:5000/skills_list', json = {\"job_titles\":{title: {\"startDate\":\"2016-10-10\",\"endDate\":\"2016-10-20\"}},\"language\":{\"language\":\"en\"}})\n",
    "    skills.append(json.loads(response.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_dict = {}\n",
    "for i in skills:\n",
    "    skills_dict.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "t = []\n",
    "for i in skills_dict:\n",
    "    s.append(skills_dict[i])\n",
    "    t.append(i)\n",
    "lista = pd.DataFrame()\n",
    "lista[\"titles\"] = t\n",
    "lista[\"skills\"] = s\n",
    "lista.to_excel(\"Jobs_To_Analyse.xls\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_title_found</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>sources</th>\n",
       "      <th>jobkeys</th>\n",
       "      <th>dates</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Intelletec</td>\n",
       "      <td>San Francisco, California, US</td>\n",
       "      <td>Intelletec</td>\n",
       "      <td>8334aee8c9dc</td>\n",
       "      <td>10/5/2020</td>\n",
       "      <td>Lead Data ScientistSan Francisco Intelletec ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Adobe Systems</td>\n",
       "      <td>San Jose, California, US</td>\n",
       "      <td>Experteer GmbH</td>\n",
       "      <td>65eefcb13370</td>\n",
       "      <td>12/5/2020</td>\n",
       "      <td>Our companyChanging the world through digital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Autogrid</td>\n",
       "      <td>Redwood City, California, US</td>\n",
       "      <td>Experteer GmbH</td>\n",
       "      <td>cf15f75b783f</td>\n",
       "      <td>12/5/2020</td>\n",
       "      <td>About AutoGrid SystemsAt AutoGrid, you will jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Data Scientist, Engineering</td>\n",
       "      <td>Google</td>\n",
       "      <td>San Francisco, California, US</td>\n",
       "      <td>Google</td>\n",
       "      <td>87dc837a9dd5</td>\n",
       "      <td>12/5/2020</td>\n",
       "      <td>As a Data Scientist, you will evaluate and imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Wish.com</td>\n",
       "      <td>San Francisco, California, US</td>\n",
       "      <td>Jobcase</td>\n",
       "      <td>c8dd3c7cf8b4</td>\n",
       "      <td>12/5/2020</td>\n",
       "      <td>At Wish, our Data Science &amp; Engineering team i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119840</td>\n",
       "      <td>pharmaceutical quality specialist</td>\n",
       "      <td>Senior Quality Compliance Technical Specialist</td>\n",
       "      <td>Amneal Pharmaceuticals, Inc.</td>\n",
       "      <td>Piscataway, New Jersey, US</td>\n",
       "      <td>Nexxt</td>\n",
       "      <td>244cb835b725</td>\n",
       "      <td>08/5/2020</td>\n",
       "      <td>Description:To provide quality oversight for R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119841</td>\n",
       "      <td>pharmaceutical quality specialist</td>\n",
       "      <td>Pharmaceutical Quality Specialist</td>\n",
       "      <td>On-Board Companies</td>\n",
       "      <td>West Point, Pennsylvania, US</td>\n",
       "      <td>JobDiva</td>\n",
       "      <td>9c9a43613be6</td>\n",
       "      <td>05/5/2020</td>\n",
       "      <td>T*7 month contract position with additional op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119842</td>\n",
       "      <td>pharmaceutical quality specialist</td>\n",
       "      <td>Senior Quality IT Specialist</td>\n",
       "      <td>Endo Pharmaceuticals</td>\n",
       "      <td>Malvern, Pennsylvania, US</td>\n",
       "      <td>Nexxt</td>\n",
       "      <td>79bfd2dcb68e</td>\n",
       "      <td>08/5/2020</td>\n",
       "      <td>Job Summary - a concise overview of the jobThe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119843</td>\n",
       "      <td>pharmaceutical quality specialist</td>\n",
       "      <td>Quality Assurance Technical Support Specialist...</td>\n",
       "      <td>coyotesourcing.com</td>\n",
       "      <td>Oostburg, Wisconsin, US</td>\n",
       "      <td>PostJobFree</td>\n",
       "      <td>6299b9c936bb</td>\n",
       "      <td>04/5/2020</td>\n",
       "      <td>Quality Assurance Technical Support Specialist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119844</td>\n",
       "      <td>water conservation technician</td>\n",
       "      <td>Water Conservation Technician</td>\n",
       "      <td>Resource Central</td>\n",
       "      <td>Denver, Colorado, US</td>\n",
       "      <td>Idealist</td>\n",
       "      <td>663dd551ad61</td>\n",
       "      <td>04/5/2020</td>\n",
       "      <td>&lt;b&gt;Position Description&lt;/b&gt;Are you seeking a s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119845 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                job_title  \\\n",
       "0                          Data scientist   \n",
       "1                          Data scientist   \n",
       "2                          Data scientist   \n",
       "3                          Data scientist   \n",
       "4                          Data scientist   \n",
       "...                                   ...   \n",
       "119840  pharmaceutical quality specialist   \n",
       "119841  pharmaceutical quality specialist   \n",
       "119842  pharmaceutical quality specialist   \n",
       "119843  pharmaceutical quality specialist   \n",
       "119844      water conservation technician   \n",
       "\n",
       "                                          job_title_found  \\\n",
       "0                                     Lead Data Scientist   \n",
       "1                                          Data Scientist   \n",
       "2                                   Senior Data Scientist   \n",
       "3                             Data Scientist, Engineering   \n",
       "4                                          Data Scientist   \n",
       "...                                                   ...   \n",
       "119840     Senior Quality Compliance Technical Specialist   \n",
       "119841                  Pharmaceutical Quality Specialist   \n",
       "119842                       Senior Quality IT Specialist   \n",
       "119843  Quality Assurance Technical Support Specialist...   \n",
       "119844                      Water Conservation Technician   \n",
       "\n",
       "                             company                       location  \\\n",
       "0                         Intelletec  San Francisco, California, US   \n",
       "1                      Adobe Systems       San Jose, California, US   \n",
       "2                           Autogrid   Redwood City, California, US   \n",
       "3                             Google  San Francisco, California, US   \n",
       "4                           Wish.com  San Francisco, California, US   \n",
       "...                              ...                            ...   \n",
       "119840  Amneal Pharmaceuticals, Inc.     Piscataway, New Jersey, US   \n",
       "119841            On-Board Companies   West Point, Pennsylvania, US   \n",
       "119842          Endo Pharmaceuticals      Malvern, Pennsylvania, US   \n",
       "119843            coyotesourcing.com        Oostburg, Wisconsin, US   \n",
       "119844              Resource Central           Denver, Colorado, US   \n",
       "\n",
       "               sources       jobkeys      dates  \\\n",
       "0           Intelletec  8334aee8c9dc  10/5/2020   \n",
       "1       Experteer GmbH  65eefcb13370  12/5/2020   \n",
       "2       Experteer GmbH  cf15f75b783f  12/5/2020   \n",
       "3               Google  87dc837a9dd5  12/5/2020   \n",
       "4              Jobcase  c8dd3c7cf8b4  12/5/2020   \n",
       "...                ...           ...        ...   \n",
       "119840           Nexxt  244cb835b725  08/5/2020   \n",
       "119841         JobDiva  9c9a43613be6  05/5/2020   \n",
       "119842           Nexxt  79bfd2dcb68e  08/5/2020   \n",
       "119843     PostJobFree  6299b9c936bb  04/5/2020   \n",
       "119844        Idealist  663dd551ad61  04/5/2020   \n",
       "\n",
       "                                              description  \n",
       "0       Lead Data ScientistSan Francisco Intelletec ha...  \n",
       "1       Our companyChanging the world through digital ...  \n",
       "2       About AutoGrid SystemsAt AutoGrid, you will jo...  \n",
       "3       As a Data Scientist, you will evaluate and imp...  \n",
       "4       At Wish, our Data Science & Engineering team i...  \n",
       "...                                                   ...  \n",
       "119840  Description:To provide quality oversight for R...  \n",
       "119841  T*7 month contract position with additional op...  \n",
       "119842  Job Summary - a concise overview of the jobThe...  \n",
       "119843  Quality Assurance Technical Support Specialist...  \n",
       "119844  <b>Position Description</b>Are you seeking a s...  \n",
       "\n",
       "[119845 rows x 8 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Salary Range\n",
    "#Intern or Full time\n",
    "#Get the years of experience\n",
    "#Get the needed certificates\n",
    "\n",
    "scraps_valid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
